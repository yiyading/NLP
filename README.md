关于自然与然和机器学习的学习心得，在机器学习的过程中，根据情况判断是否需要学习吴恩达老师的《深度学习》

关于**ML-**系列
1. 参考的是黄海广前辈整理的笔记和视频，源课程来自吴恩达老师在coursera上的《机器学习》。
2. 参考的曹建《人工智能实践》，因为曹老师平时给我们上课时讲的都是实战，非常建议意看看，该课程可在mooc观看

如果想要看更加详细的视频和源码，请点击下方的git地址
> git地址：https://github.com/yiyading/Coursera-ML-AndrewNg-Notes

吴恩达老师课程地址：
> https://www.coursera.org/course/ml

曹健老师mooc:
> https://www.icourse163.org/learn/PKU-1002536002#/learn/announce

[ML-first](https://github.com/yiyading/NLP-and-ML/blob/master/ML-first.md):
> 1. 通过房价预测和癌症介绍监督学习中的回归问题和分类问题的定义。
> 2. 介绍无监督学习的特征->聚类算法。
> 3. 通过房价预测介绍单变量线性回归的模型建立和代价函数/梯度下降。
> 4. 介绍单变量线性回归中的梯度下降算法。

[ML-second](https://github.com/yiyading/NLP-and-ML/blob/master/ML-second.md)
> 1. 介绍多变量线性回归中由多变量构成的多特征及其梯度下降。
> 2. 介绍多变量线性回归梯度下降中的特征缩放和学习率。
> 3. 介绍多变量线性回归中由特征构成的多项式方程和正规方程。

[ML-third](https://github.com/yiyading/NLP-and-ML/blob/master/ML-third.md)
> 1. 介绍逻辑回归中的二元分类与决策边界
> 2. 介绍重定义代价函数的目的和距离
> 3. 总结了代价函数和梯度下降的迭代公式
> 4. 从二分类扩展到多类别分类问题

[ML-fifth](https://github.com/yiyading/NLP-and-ML/blob/master/ML-fifth.md)主要介绍NN网络的构成以及NN网络中如何使用梯度下降和梯度检验的作用

[ML-sixth](https://github.com/yiyading/NLP-and-ML/blob/master/ML-sixth.md)主要介绍对模型出现bias/variance问题时的优化方法，以及何时选择这些优化方法

[ML-seventh](https://github.com/yiyading/NLP-and-ML/blob/master/ML-seventh.md)：
> 1. 通过描述搭建垃圾邮件分类器的原理，来说明误差分析（error analysis）的优缺点。
> 2. 通过类偏斜问题查准率和查全率的概念，并引出**F1 score**作为权衡阈值的标准。
> 3. 通过对逻辑回归代价函数的修改，构建SVM；通过将正则化参数λ修改为C得到SVM的代价函数。
> 4. 通过作图说明SVM为什么被叫做大间距分类器，即嵌入安全间距因子的作用——鲁棒性。
> 5. 通过数学分析说明SVM如何选择决策边界。即在满足限制条件的前提下，极小化代价函数。
> 6. 通过核函数得到非线性决策边界，并介绍高斯核函数的similarity的实现。
> 7. 介绍如何使用SVM，在不同的情况下如何选择SVM和逻辑回归。
