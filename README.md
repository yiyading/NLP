自然与然和机器学习的学习心得，在机器学习的过程中，根据情况判断是否需要学习吴恩达老师的《深度学习》

关于**ML-**系列

吴恩达老师课程地址：
> https://www.coursera.org/course/ml

曹健老师mooc:
> https://www.icourse163.org/learn/PKU-1002536002#/learn/announce

[ML-first](ML-first):
> 1. 通过房价预测和癌症介绍监督学习中的回归问题和分类问题的定义。
> 2. 介绍无监督学习的特征->聚类算法。
> 3. 通过房价预测介绍单变量线性回归的模型建立和代价函数/梯度下降。
> 4. 介绍单变量线性回归中的梯度下降算法。

[ML-second](ML-second)
> 1. 介绍多变量线性回归中由多变量构成的多特征及其梯度下降。
> 2. 介绍多变量线性回归梯度下降中的特征缩放和学习率。
> 3. 介绍多变量线性回归中由特征构成的多项式方程和正规方程。

[ML-third](https://github.com/yiyading/NLP-and-ML/blob/master/ML-third.md)
> 1. 介绍逻辑回归中的二元分类与决策边界
> 2. 介绍重定义代价函数的目的和距离
> 3. 总结了代价函数和梯度下降的迭代公式
> 4. 从二分类扩展到多类别分类问题

[ML-fourth](https://github.com/yiyading/NLP-and-ML/blob/master/ML-fourth.md)
> 1. 介绍L1和L2正则化
> 2. 介绍L1和L2正则化在线性回归和逻辑回归中的应用方程

[ML-fifth](https://github.com/yiyading/NLP-and-ML/blob/master/ML-fifth.md)主要介绍NN网络的构成以及NN网络中如何使用梯度下降和梯度检验的作用
> 1. 介绍NN网络的构成
> 2. NN网络如何使用梯度下降
> 3. 梯度检验的作用
> **反向传播中的梯度通过逐层进行下降**

[ML-sixth](https://github.com/yiyading/NLP-and-ML/blob/master/ML-sixth.md)
> 1. 介绍如何评估一个模型的好坏 
> 2. 介绍模型的选择和交叉验证数据集的作用
> 3. 介绍偏差（bias）和方差（variance）的产生原因以及解决方案

[ML-seventh](https://github.com/yiyading/NLP-and-ML/blob/master/ML-seventh.md)：
> 1. 通过描述搭建垃圾邮件分类器的原理，来说明误差分析（error analysis）的优缺点。
> 2. 通过类偏斜问题查准率和查全率的概念，并引出**F1 score**作为权衡阈值的标准。
> 3. 通过对逻辑回归代价函数的修改，构建SVM；通过将正则化参数λ修改为C得到SVM的代价函数。
> 4. 通过作图说明SVM为什么被叫做大间距分类器，即嵌入安全间距因子的作用——鲁棒性。
> 5. 通过数学分析说明SVM如何选择决策边界。即在满足限制条件的前提下，极小化代价函数。
> 6. 通过核函数得到非线性决策边界，并介绍高斯核函数的similarity的实现。
> 7. 介绍如何使用SVM，在不同的情况下如何选择SVM和逻辑回归。

[ML-eighth](ML-eighth.md)
> 1. 介绍非监督学习的聚类算法
> 2. 介绍聚类算法中的K-均值算法
> 3. 介绍K-均值函数的代价函数，即寻找所有数据到关联聚类点的最小平均距离
> 4. 介绍K-均值算法初值的选择方式和通过**肘部法则**寻找聚类数
> 5. 介绍降维的方法论和降维的目的
> 6. 介绍PCA降维算法及其如何使用




