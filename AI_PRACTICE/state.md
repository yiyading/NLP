# 神经网络模型
1.损失函数
> 均方差损失函数<br>
> 自定义损失函数

2.梯度下降

3.学习率

4.反向传播更新参数
> 使用梯度下降逐步更新，或者使用正规方程

5.激活函数
> Sigmod: 易造成梯度消失<br>
> Tanh:   易造成梯度消失<br>
> Relu

6.正则化：减少过拟合
> L1正则化：使很多参数变为0 -> 稀疏参数
> L2正则化：减小参数值的大小 -> 降低复杂度

7.优化器
> 反向传播参数更新时使用的一种方法

8.归一化和标准化
> 防止损失函数等高线过扁，提高收敛速度

9.tf.keras搭建网络八股
> import -> x_train,y_train ->
